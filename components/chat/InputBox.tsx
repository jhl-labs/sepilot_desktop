'use client';

import { useState, KeyboardEvent, useRef, useEffect, useCallback } from 'react';
import { Textarea } from '@/components/ui/textarea';
import { Button } from '@/components/ui/button';
import {
  Send,
  Square,
  ImagePlus,
  X,
  Sparkles,
  ChevronDown,
  Zap,
  Brain,
  Network,
  Database,
  Wrench,
  Code,
} from 'lucide-react';
import { useChatStore } from '@/lib/store/chat-store';
import { initializeLLMClient } from '@/lib/llm/client';
import { initializeComfyUIClient } from '@/lib/comfyui/client';
import { generateConversationTitle, shouldGenerateTitle } from '@/lib/chat/title-generator';
import { isElectron } from '@/lib/platform';
import { getWebLLMClient, configureWebLLMClient } from '@/lib/llm/web-client';
import { ImageAttachment, Message, ToolCall, ComfyUIConfig, NetworkConfig, LLMConfig } from '@/types';
import { ToolApprovalDialog } from './ToolApprovalDialog';
import { ImageGenerationProgressBar } from './ImageGenerationProgressBar';
import { LLMStatusBar, type ToolInfo } from './LLMStatusBar';
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuTrigger,
} from '@/components/ui/dropdown-menu';
import { Tooltip, TooltipContent, TooltipProvider, TooltipTrigger } from '@/components/ui/tooltip';

export function InputBox() {
  const [input, setInput] = useState('');
  const [error, setError] = useState<string | null>(null);
  const [selectedImages, setSelectedImages] = useState<ImageAttachment[]>([]);
  const [comfyUIAvailable, setComfyUIAvailable] = useState(false);
  const [comfyUIConfig, setComfyUIConfig] = useState<ComfyUIConfig | null>(null);
  const [llmConfig, setLlmConfig] = useState<LLMConfig | null>(null);
  const [mounted, setMounted] = useState(false);
  const [isComposing, setIsComposing] = useState(false);
  const [isDragging, setIsDragging] = useState(false);
  const [tools, setTools] = useState<ToolInfo[]>([]);
  const textareaRef = useRef<HTMLTextAreaElement>(null);
  const abortControllerRef = useRef<AbortController | null>(null);
  const streamingConversationIdRef = useRef<string | null>(null);
  const dropZoneRef = useRef<HTMLDivElement>(null);

  const {
    addMessage,
    updateMessage,
    activeConversationId,
    createConversation,
    streamingConversations,
    startStreaming,
    stopStreaming,
    messages,
    thinkingMode,
    enableRAG,
    enableTools,
    setThinkingMode,
    setEnableRAG,
    setEnableTools,
    getGraphConfig,
    conversations,
    updateConversationTitle,
    pendingToolApproval,
    setPendingToolApproval,
    clearPendingToolApproval,
    alwaysApproveToolsForSession,
    setAlwaysApproveToolsForSession,
    imageGenerationProgress,
    setImageGenerationProgress,
    clearImageGenerationProgress,
    enableImageGeneration,
    setEnableImageGeneration,
  } = useChatStore();

  // Determine if any conversation is currently streaming
  const isStreaming = activeConversationId ? streamingConversations.has(activeConversationId) : false;

  // Get image generation progress for current conversation
  const currentImageGenProgress = activeConversationId
    ? imageGenerationProgress.get(activeConversationId)
    : undefined;

  // Handle LLM config update from LLMStatusBar
  const handleConfigUpdate = async (updatedConfig: LLMConfig) => {
    setLlmConfig(updatedConfig);

    // Save to storage
    try {
      if (isElectron() && window.electronAPI) {
        // Load current config and update only llm
        const currentConfig = await window.electronAPI.config.load();
        if (currentConfig.success && currentConfig.data) {
          const mergedConfig = { ...currentConfig.data, llm: updatedConfig };
          await window.electronAPI.config.save(mergedConfig);
        }
        initializeLLMClient(updatedConfig);
      } else {
        localStorage.setItem('sepilot_llm_config', JSON.stringify(updatedConfig));
        configureWebLLMClient(updatedConfig);
      }
      // Dispatch event to notify other components
      window.dispatchEvent(new CustomEvent('sepilot:config-updated', { detail: { llm: updatedConfig } }));
    } catch (error) {
      console.error('Failed to save LLM config:', error);
    }
  };

  // Handle compact conversation (summarize older messages)
  const handleCompact = async () => {
    // TODO: Implement context compaction/summarization
    console.log('[InputBox] Compact requested - not yet implemented');
  };

  // Set mounted state to avoid hydration mismatch with Tooltip
  useEffect(() => {
    setMounted(true);
  }, []);

  // Load available tools (MCP + builtin)
  useEffect(() => {
    const loadTools = async () => {
      if (!isElectron() || !window.electronAPI) {
        return;
      }

      try {
        // Get MCP tools
        const mcpResult = await window.electronAPI.mcp.getAllTools();
        const mcpTools: ToolInfo[] = mcpResult.success && mcpResult.data
          ? mcpResult.data.map((tool: any) => ({
              name: tool.name,
              description: tool.description,
              serverName: tool.serverName,
            }))
          : [];

        // Get builtin tools
        const builtinTools: ToolInfo[] = [
          { name: 'file_read', description: 'Read file contents from the filesystem', serverName: 'builtin' },
          { name: 'file_write', description: 'Write content to a file (overwrites existing content)', serverName: 'builtin' },
          { name: 'file_edit', description: 'Edit a file by replacing old text with new text', serverName: 'builtin' },
          { name: 'file_list', description: 'List files in a directory', serverName: 'builtin' },
        ];

        // Combine all tools
        setTools([...mcpTools, ...builtinTools]);
      } catch (error) {
        console.error('[InputBox] Failed to load tools:', error);
      }
    };

    loadTools();
  }, []);

  // Listen for file drop events from ChatArea
  useEffect(() => {
    const handleFileDrop = (e: CustomEvent<{ textContents: string[]; imageFiles: { filename: string; mimeType: string; base64: string }[] }>) => {
      const { textContents, imageFiles } = e.detail;

      if (textContents.length > 0) {
        const combinedText = textContents.join('\n\n');
        setInput((prev) => (prev ? `${prev}\n\n${combinedText}` : combinedText));
      }

      if (imageFiles.length > 0) {
        const newImages: ImageAttachment[] = imageFiles.map((img) => ({
          id: `drop-${Date.now()}-${Math.random()}`,
          path: '',
          filename: img.filename,
          mimeType: img.mimeType,
          base64: img.base64,
        }));
        setSelectedImages((prev) => [...prev, ...newImages]);
      }
    };

    window.addEventListener('sepilot:file-drop', handleFileDrop as EventListener);
    return () => {
      window.removeEventListener('sepilot:file-drop', handleFileDrop as EventListener);
    };
  }, []);

  // Load LLM and ComfyUI config on mount
  useEffect(() => {
    const loadConfig = async () => {
      if (typeof window === 'undefined') {
        return;
      }

      try {
        if (isElectron() && window.electronAPI) {
          // Electron: SQLiteì—ì„œ ë¡œë“œ
          const result = await window.electronAPI.config.load();
          if (result.success && result.data) {
            // Initialize LLM client
            if (result.data.llm) {
              initializeLLMClient(result.data.llm);
              setLlmConfig(result.data.llm);
            }

            // Initialize ComfyUI client
            if (result.data.comfyUI) {
              initializeComfyUIClient(result.data.comfyUI);
              // Store ComfyUI config for IPC
              setComfyUIConfig(result.data.comfyUI);
              // Check if ComfyUI is enabled and has httpUrl configured
              const isAvailable = result.data.comfyUI.enabled && !!result.data.comfyUI.httpUrl;
              setComfyUIAvailable(isAvailable);
              console.log('[InputBox] ComfyUI client initialized:', {
                enabled: result.data.comfyUI.enabled,
                httpUrl: result.data.comfyUI.httpUrl,
                available: isAvailable,
              });
            } else {
              setComfyUIAvailable(false);
              setComfyUIConfig(null);
            }
          }
        } else {
          // Web: localStorageì—ì„œ ë¡œë“œ
          const savedConfig = localStorage.getItem('sepilot_llm_config');
          if (savedConfig) {
            const config = JSON.parse(savedConfig);
            configureWebLLMClient(config);
            setLlmConfig(config);
          }

          // Also try to load ComfyUI config from localStorage
          const savedComfyConfig = localStorage.getItem('sepilot_comfyui_config');
          if (savedComfyConfig) {
            const config = JSON.parse(savedComfyConfig);
            initializeComfyUIClient(config);
            setComfyUIConfig(config);
            const isAvailable = config.enabled && !!config.httpUrl;
            setComfyUIAvailable(isAvailable);
          } else {
            setComfyUIAvailable(false);
            setComfyUIConfig(null);
          }
        }
      } catch (error) {
        console.error('Failed to load config:', error);
      }
    };

    loadConfig();

    // Listen for storage changes (when settings are updated)
    const handleStorageChange = (e: StorageEvent) => {
      if (e.key === 'sepilot_comfyui_config' && e.newValue) {
        try {
          const config = JSON.parse(e.newValue);
          initializeComfyUIClient(config);
          setComfyUIConfig(config);
          const isAvailable = config.enabled && !!config.httpUrl;
          setComfyUIAvailable(isAvailable);
          console.log('[InputBox] ComfyUI config updated from storage:', {
            enabled: config.enabled,
            httpUrl: config.httpUrl,
            available: isAvailable,
          });
        } catch (error) {
          console.error('Failed to parse ComfyUI config from storage:', error);
        }
      }
    };

    // Custom event listener for config updates (Electron environment)
    const handleConfigUpdate = ((e: CustomEvent) => {
      const { comfyUI, llm } = e.detail || {};

      // LLM ì„¤ì • ì—…ë°ì´íŠ¸
      if (llm) {
        setLlmConfig(llm);
        if (isElectron() && window.electronAPI) {
          // Electron: IPCë¥¼ í†µí•´ LLM í´ë¼ì´ì–¸íŠ¸ ì¬ì´ˆê¸°í™”
          initializeLLMClient(llm);
          console.log('[InputBox] LLM config updated from event (Electron):', {
            provider: llm.provider,
            model: llm.model,
          });
        } else {
          // Web: WebLLMClient ì¬ì´ˆê¸°í™”
          configureWebLLMClient(llm);
          console.log('[InputBox] LLM config updated from event (Web):', {
            provider: llm.provider,
            model: llm.model,
          });
        }
      }

      // ComfyUI ì„¤ì • ì—…ë°ì´íŠ¸
      if (comfyUI) {
        initializeComfyUIClient(comfyUI);
        setComfyUIConfig(comfyUI);
        const isAvailable = comfyUI.enabled && !!comfyUI.httpUrl;
        setComfyUIAvailable(isAvailable);
        console.log('[InputBox] ComfyUI config updated from event:', {
          enabled: comfyUI.enabled,
          httpUrl: comfyUI.httpUrl,
          available: isAvailable,
        });
      }
    }) as EventListener;

    window.addEventListener('storage', handleStorageChange);
    window.addEventListener('sepilot:config-updated', handleConfigUpdate);

    return () => {
      window.removeEventListener('storage', handleStorageChange);
      window.removeEventListener('sepilot:config-updated', handleConfigUpdate);
    };
  }, []);

  // Auto-resize textarea
  useEffect(() => {
    if (textareaRef.current) {
      textareaRef.current.style.height = 'auto';
      textareaRef.current.style.height = `${textareaRef.current.scrollHeight}px`;
    }
  }, [input]);

  // Auto-switch to Instant mode when images are selected or image generation is enabled
  // (Multimodal models and image generation require using agent.ts which works best with Instant mode)
  useEffect(() => {
    if ((selectedImages.length > 0 || enableImageGeneration) && thinkingMode !== 'instant') {
      const reason = enableImageGeneration ? 'image generation enabled' : 'images detected';
      console.log(`[InputBox] ${reason}, switching to Instant mode for multimodal support`);
      setThinkingMode('instant');
    }
  }, [selectedImages, enableImageGeneration, thinkingMode, setThinkingMode]);

  // Stop streaming handler
  const handleStop = useCallback(async () => {
    console.log('[InputBox] handleStop called');

    if (abortControllerRef.current) {
      console.log('[InputBox] Aborting AbortController');
      abortControllerRef.current.abort();
    }

    // Use activeConversationId instead of ref to support both InputBox and ChatArea streaming
    const conversationId = streamingConversationIdRef.current || activeConversationId;
    console.log('[InputBox] Streaming conversationId (ref):', streamingConversationIdRef.current);
    console.log('[InputBox] Active conversationId:', activeConversationId);
    console.log('[InputBox] Using conversationId:', conversationId);

    if (conversationId) {
      // Abort streaming in Main Process
      if (isElectron() && typeof window !== 'undefined' && window.electronAPI?.langgraph) {
        try {
          console.log('[InputBox] Sending abort to Main Process for:', conversationId);
          const result = await window.electronAPI.langgraph.abort(conversationId);
          console.log('[InputBox] Abort result:', result);
        } catch (error) {
          console.error('[InputBox] Failed to abort stream:', error);
        }
        window.electronAPI.langgraph.removeAllStreamListeners();
      }

      // Stop streaming UI state
      console.log('[InputBox] Stopping streaming UI state');
      stopStreaming(conversationId);

      // Reset refs
      streamingConversationIdRef.current = null;
      abortControllerRef.current = null;
    } else {
      console.warn('[InputBox] No active conversationId found for abort');
    }
  }, [stopStreaming, activeConversationId]);

  // Handle Esc key to stop streaming
  useEffect(() => {
    const handleKeyDown = (e: globalThis.KeyboardEvent) => {
      if (e.key === 'Escape' && isStreaming) {
        handleStop();
      }
    };

    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [isStreaming, handleStop]);

  // Handle image selection
  const handleImageSelect = async () => {
    if (!isElectron() || !window.electronAPI) {
      setError('Image upload is only available in the desktop app');
      return;
    }

    try {
      const result = await window.electronAPI.file.selectImages();
      if (result.success && result.data && result.data.length > 0) {
        setSelectedImages((prev) => [...prev, ...(result.data || [])]);
      }
    } catch (error: any) {
      console.error('Failed to select images:', error);
      setError(error.message || 'Failed to select images');
    }
  };

  // Remove selected image
  const handleRemoveImage = (imageId: string) => {
    setSelectedImages((prev) => prev.filter((img) => img.id !== imageId));
  };

  // Handle clipboard paste
  const handlePaste = async (e: React.ClipboardEvent<HTMLTextAreaElement>) => {
    const items = e.clipboardData?.items;
    if (!items) return;

    const imageFiles: File[] = [];

    // í´ë¦½ë³´ë“œ ì•„ì´í…œì—ì„œ ì´ë¯¸ì§€ ì°¾ê¸°
    for (let i = 0; i < items.length; i++) {
      const item = items[i];
      if (item.type.startsWith('image/')) {
        const file = item.getAsFile();
        if (file) {
          imageFiles.push(file);
        }
      }
    }

    if (imageFiles.length === 0) return;

    // ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸° ë°©ì§€
    e.preventDefault();

    // ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€
    for (const file of imageFiles) {
      try {
        const reader = new FileReader();
        reader.onload = (event) => {
          const base64 = event.target?.result as string;
          const newImage: ImageAttachment = {
            id: `clipboard-${Date.now()}-${Math.random()}`,
            path: '',
            filename: file.name || `clipboard-image-${Date.now()}.${file.type.split('/')[1]}`,
            mimeType: file.type,
            base64,
          };
          setSelectedImages((prev) => [...prev, newImage]);
        };
        reader.onerror = () => {
          setError('í´ë¦½ë³´ë“œ ì´ë¯¸ì§€ë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤');
        };
        reader.readAsDataURL(file);
      } catch (error: any) {
        console.error('Failed to read clipboard image:', error);
        setError(error.message || 'í´ë¦½ë³´ë“œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤');
      }
    }
  };

  // Handle drag events for text files
  const handleDragOver = (e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
  };

  const handleDragEnter = (e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragging(true);
  };

  const handleDragLeave = (e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    // dropZone ë°”ê¹¥ìœ¼ë¡œ ë‚˜ê°ˆ ë•Œë§Œ isDraggingì„ falseë¡œ ì„¤ì •
    if (dropZoneRef.current && !dropZoneRef.current.contains(e.relatedTarget as Node)) {
      setIsDragging(false);
    }
  };

  const handleDrop = async (e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragging(false);

    const files = Array.from(e.dataTransfer.files);
    if (files.length === 0) return;

    const textContents: string[] = [];

    for (const file of files) {
      // í…ìŠ¤íŠ¸ íŒŒì¼ì¸ì§€ í™•ì¸
      const isTextFile =
        file.type.startsWith('text/') ||
        file.name.endsWith('.txt') ||
        file.name.endsWith('.md') ||
        file.name.endsWith('.json') ||
        file.name.endsWith('.js') ||
        file.name.endsWith('.ts') ||
        file.name.endsWith('.tsx') ||
        file.name.endsWith('.jsx') ||
        file.name.endsWith('.css') ||
        file.name.endsWith('.html') ||
        file.name.endsWith('.xml') ||
        file.name.endsWith('.yaml') ||
        file.name.endsWith('.yml') ||
        file.name.endsWith('.py') ||
        file.name.endsWith('.java') ||
        file.name.endsWith('.c') ||
        file.name.endsWith('.cpp') ||
        file.name.endsWith('.h') ||
        file.name.endsWith('.sh') ||
        file.name.endsWith('.sql') ||
        file.name.endsWith('.csv');

      if (isTextFile) {
        try {
          const text = await file.text();
          textContents.push(`ğŸ“„ **${file.name}**\n\`\`\`\n${text}\n\`\`\``);
        } catch (error) {
          console.error(`Failed to read file ${file.name}:`, error);
          setError(`íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${file.name}`);
        }
      } else if (file.type.startsWith('image/')) {
        // ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬
        try {
          const reader = new FileReader();
          reader.onload = (event) => {
            const base64 = event.target?.result as string;
            const newImage: ImageAttachment = {
              id: `drop-${Date.now()}-${Math.random()}`,
              path: '',
              filename: file.name,
              mimeType: file.type,
              base64,
            };
            setSelectedImages((prev) => [...prev, newImage]);
          };
          reader.readAsDataURL(file);
        } catch (error) {
          console.error(`Failed to read image ${file.name}:`, error);
        }
      } else {
        setError(`ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: ${file.name}`);
      }
    }

    if (textContents.length > 0) {
      const combinedText = textContents.join('\n\n');
      setInput((prev) => (prev ? `${prev}\n\n${combinedText}` : combinedText));
    }
  };

  const handleSend = async () => {
    if ((!input.trim() && selectedImages.length === 0) || isStreaming) {
      return;
    }

    setError(null);

    // Create conversation if none exists and get the ID
    let targetConversationId = activeConversationId;
    if (!targetConversationId) {
      targetConversationId = await createConversation();
    }

    const userMessage = input.trim();
    const messagImages = selectedImages.length > 0 ? [...selectedImages] : undefined;
    setInput('');
    setSelectedImages([]);

    // Execute streaming in background (don't await - allows user to switch conversations)
    executeStreamingInBackground(targetConversationId, userMessage, messagImages);
  };

  const executeStreamingInBackground = async (
    conversationId: string,
    userMessage: string,
    messagImages?: ImageAttachment[]
  ) => {
    // Variables for streaming animation
    let accumulatedContent = '';
    let accumulatedMessage: Partial<Message> = {};
    let pendingUpdate = false;
    let rafId: number | null = null;

    try {
      // Add user message with images if present (specify conversation ID)
      await addMessage(
        {
          role: 'user',
          content: userMessage,
          images: messagImages,
        },
        conversationId
      );

      // Prepare messages for LLM (include history)
      const allMessages = [
        ...messages,
        {
          id: 'temp',
          role: 'user' as const,
          content: userMessage,
          created_at: Date.now(),
          images: messagImages, // ì´ë¯¸ì§€ í¬í•¨!
        },
      ];

      // Create empty assistant message for streaming (specify conversation ID)
      const assistantMessage = await addMessage(
        {
          role: 'assistant',
          content: '',
        },
        conversationId
      );

      const assistantMessageId = assistantMessage.id;

      // Use conversation-specific streaming state
      startStreaming(conversationId, assistantMessageId);

      // Track streaming conversation ID for abort handling
      streamingConversationIdRef.current = conversationId;

      // Create abort controller for cancellation
      abortControllerRef.current = new AbortController();

      // ë¶€ë“œëŸ¬ìš´ UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ RAF ê¸°ë°˜ ë°°ì¹­
      // ëª¨ë“  ì²­í¬ë¥¼ ì¦‰ì‹œ ëˆ„ì í•˜ê³ , RAFë¡œ ë Œë”ë§ì„ ë°°ì¹­
      let updateScheduled = false;

      const scheduleUpdate = (messageUpdates: Partial<Message>, force = false) => {
        accumulatedMessage = { ...accumulatedMessage, ...messageUpdates };

        if (force) {
          // ê°•ì œ ì—…ë°ì´íŠ¸ (ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì‹œ)
          if (rafId !== null) {
            cancelAnimationFrame(rafId);
            rafId = null;
          }
          updateMessage(assistantMessageId, accumulatedMessage, conversationId);
          updateScheduled = false;
          return;
        }

        // RAFê°€ ì´ë¯¸ ì˜ˆì•½ë˜ì–´ ìˆìœ¼ë©´, ë‹¤ìŒ í”„ë ˆì„ì—ì„œ ìµœì‹  ìƒíƒœë¡œ ì—…ë°ì´íŠ¸ë¨
        if (updateScheduled) {
          return;
        }

        updateScheduled = true;
        rafId = requestAnimationFrame(() => {
          updateMessage(assistantMessageId, accumulatedMessage, conversationId);
          updateScheduled = false;
          rafId = null;
        });
      };

      // Stream response from IPC (Electron) or Web
      try {
        if (isElectron() && typeof window !== 'undefined' && window.electronAPI?.langgraph) {
          // Electron: Use IPC to stream LangGraph responses (CORS ì—†ìŒ)
          const graphConfig = getGraphConfig();

          // Setup stream event listeners
          // ì´ë²¤íŠ¸ì— í¬í•¨ëœ conversationIdë¡œ í•„í„°ë§í•˜ì—¬ ë‹¤ë¥¸ ëŒ€í™”ì˜ ì´ë²¤íŠ¸ ë¬´ì‹œ
          const eventHandler = window.electronAPI.langgraph.onStreamEvent((event: any) => {
            try {
              // Filter events by conversationId - ignore events from other conversations
              if (event.conversationId && event.conversationId !== conversationId) {
                return;
              }

              if (abortControllerRef.current?.signal.aborted) {
                return;
              }

              // Handle real-time streaming chunks from LLM
              if (event.type === 'streaming' && event.chunk) {
                accumulatedContent += event.chunk;
                scheduleUpdate({ content: accumulatedContent });
                return;
              }

              // Handle image generation progress
              if (event.type === 'image_progress' && event.progress) {
                const progress = event.progress;

                // Update store with image generation progress
                setImageGenerationProgress({
                  conversationId,
                  messageId: assistantMessageId,
                  status: progress.status,
                  message: progress.message,
                  progress: progress.progress || 0,
                  currentStep: progress.currentStep,
                  totalSteps: progress.totalSteps,
                });

                // Update UI with progress status
                if (progress.status === 'executing' || progress.status === 'queued') {
                  scheduleUpdate({ content: progress.message });
                } else if (progress.status === 'completed') {
                  clearImageGenerationProgress(conversationId);
                } else if (progress.status === 'error') {
                  clearImageGenerationProgress(conversationId);
                  scheduleUpdate({ content: `âŒ ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: ${progress.message}` });
                }
                return;
              }

              // Handle tool approval request (Human-in-the-loop)
              if (event.type === 'tool_approval_request') {
                console.log('[InputBox] Tool approval request received:', event.toolCalls);

                // Auto-approve if session-wide approval is enabled (Claude Code style)
                const currentStore = useChatStore.getState();
                if (currentStore.alwaysApproveToolsForSession) {
                  console.log('[InputBox] Auto-approving tools (session-wide approval enabled)');
                  (async () => {
                    try {
                      if (isElectron() && window.electronAPI?.langgraph) {
                        await window.electronAPI.langgraph.respondToolApproval(
                          event.conversationId,
                          true
                        );
                      }
                    } catch (error) {
                      console.error('[InputBox] Failed to auto-approve tools:', error);
                    }
                  })();
                  return;
                }

                setPendingToolApproval({
                  conversationId: event.conversationId,
                  messageId: event.messageId,
                  toolCalls: event.toolCalls,
                  timestamp: Date.now(),
                });
                scheduleUpdate({ content: 'ğŸ”” ë„êµ¬ ì‹¤í–‰ ìŠ¹ì¸ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...' });
                return;
              }

              // Handle tool approval result
              if (event.type === 'tool_approval_result') {
                console.log('[InputBox] Tool approval result:', event.approved);
                clearPendingToolApproval();
                if (!event.approved) {
                  scheduleUpdate({ content: 'âŒ ë„êµ¬ ì‹¤í–‰ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.' });
                }
                return;
              }

              // Show graph node execution status for Agent mode (when tools are enabled)
              if (enableTools && event.type === 'node') {
                  let nodeStatusMessage = '';

                  // Generate node: Show AI thinking
                  if (event.node === 'generate') {
                    nodeStatusMessage = 'ğŸ¤– AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...';

                    // If there are tool calls, show them
                    if (event.data?.messages?.[0]?.tool_calls) {
                      const toolNames = event.data.messages[0].tool_calls
                        .map((tc: any) => tc.name)
                        .join(', ');
                      nodeStatusMessage = `ğŸ¤– AIê°€ ë„êµ¬ ì‚¬ìš©ì„ ê³„íší•˜ê³  ìˆìŠµë‹ˆë‹¤: ${toolNames}`;
                    }
                  }

                  // Tools node: Show tool execution
                  else if (event.node === 'tools') {
                    const toolResults = event.data?.toolResults || [];
                    if (toolResults.length > 0) {
                      const toolNames = toolResults.map((tr: any) => tr.toolName).join(', ');
                      const hasError = toolResults.some((tr: any) => tr.error);
                      const hasImageGen = toolNames.includes('generate_image');

                      if (hasImageGen) {
                        // ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ ë˜ëŠ” ì˜¤ë¥˜
                        clearImageGenerationProgress(conversationId);
                      }

                      if (hasError) {
                        nodeStatusMessage = `âš ï¸ ë„êµ¬ ì‹¤í–‰ ì¤‘ ì¼ë¶€ ì˜¤ë¥˜ ë°œìƒ: ${toolNames}`;
                      } else {
                        nodeStatusMessage = `âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ: ${toolNames}`;
                      }
                    } else {
                      // ë„êµ¬ ì‹¤í–‰ ì‹œì‘ - ë©”ì‹œì§€ì—ì„œ ì´ë¯¸ì§€ ìƒì„± ì—¬ë¶€ í™•ì¸
                      const recentMessages = event.data?.messages || [];
                      const hasImageGenCall = recentMessages.some((msg: any) =>
                        msg.tool_calls?.some((tc: any) => tc.name === 'generate_image')
                      );

                      if (hasImageGenCall) {
                        nodeStatusMessage = 'ğŸ¨ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...';
                        setImageGenerationProgress({
                          conversationId,
                          messageId: assistantMessageId,
                          status: 'queued',
                          message: 'ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ì„ ì¤€ë¹„í•˜ëŠ” ì¤‘...',
                          progress: 0,
                        });
                      } else {
                        nodeStatusMessage = 'ğŸ”§ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...';
                      }
                    }
                  }

                  // Reporter node: Final summary
                  else if (event.node === 'reporter') {
                    nodeStatusMessage = 'ğŸ“Š ìµœì¢… ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...';
                  }

                  if (nodeStatusMessage) {
                    console.log(`[InputBox] Node execution: ${event.node} - ${nodeStatusMessage}`);
                    scheduleUpdate({ content: nodeStatusMessage });
                  }
                }

                // ê° ë…¸ë“œì˜ ì‹¤í–‰ ê²°ê³¼ì—ì„œ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
                // Coding Agentì˜ ëª¨ë“  ê³¼ì •ì„ Claude Code ìŠ¤íƒ€ì¼ë¡œ í‘œì‹œ
                if (event.type === 'node' && event.data?.messages) {
                  const allMessages = event.data.messages;
                  if (allMessages && allMessages.length > 0) {
                    // Convert all messages to a single display content (Claude Code style)
                    let displayContent = '';

                    for (let i = 0; i < allMessages.length; i++) {
                      const msg = allMessages[i];

                      // Skip user messages (already displayed separately)
                      if (msg.role === 'user') {
                        continue;
                      }

                      // Assistant message with tool calls
                      if (msg.role === 'assistant' && msg.tool_calls && msg.tool_calls.length > 0) {
                        if (msg.content) {
                          displayContent += `ğŸ¤” **Thinking**\n\n${msg.content}\n\n`;
                        }
                        displayContent += `ğŸ”§ **Using tools:**\n`;
                        for (const toolCall of msg.tool_calls) {
                          displayContent += `- \`${toolCall.name}\`\n`;
                        }
                        displayContent += '\n';
                        continue;
                      }

                      // Tool result messages
                      if (msg.role === 'tool' && msg.tool_call_id) {
                        const toolName = msg.name || 'tool';
                        displayContent += `âœ… **Tool result** (\`${toolName}\`)\n\n`;
                        if (msg.content) {
                          // Truncate long results
                          const truncated = msg.content.length > 500
                            ? msg.content.substring(0, 500) + '...\n\n*(truncated)*'
                            : msg.content;
                          displayContent += `\`\`\`\n${truncated}\n\`\`\`\n\n`;
                        }
                        continue;
                      }

                      // Final assistant message (no tool calls)
                      if (msg.role === 'assistant' && (!msg.tool_calls || msg.tool_calls.length === 0)) {
                        if (msg.content) {
                          displayContent += `${msg.content}\n\n`;
                        }
                      }
                    }

                    // Update with formatted content
                    scheduleUpdate({
                      content: displayContent.trim(),
                      referenced_documents: allMessages[allMessages.length - 1]?.referenced_documents
                    });
                  }
                }

                // Extract generated images from tool results
                if (event.type === 'node' && event.node === 'tools' && event.data?.toolResults) {
                  const toolResults = event.data.toolResults;
                  const generatedImages: ImageAttachment[] = [];

                  console.log('[InputBox] Processing tool results:', toolResults);

                  // Show tool completion status
                  const toolNames = toolResults.map((tr: any) => tr.toolName).join(', ');
                  const hasImageGeneration = toolResults.some(
                    (tr: any) => tr.toolName === 'generate_image'
                  );

                  // ì´ë¯¸ì§€ ìƒì„± ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
                  if (hasImageGeneration) {
                    clearImageGenerationProgress(conversationId);
                  }

                  const statusMessage = `âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ: ${toolNames}\n\në‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...`;
                  scheduleUpdate({ content: statusMessage });

                  for (const toolResult of toolResults) {
                    if (toolResult.toolName === 'generate_image' && toolResult.result) {
                      try {
                        let resultData;

                        // Safe JSON parsing with better error handling
                        if (typeof toolResult.result === 'string') {
                          try {
                            // Try to parse as JSON
                            resultData = JSON.parse(toolResult.result);
                          } catch (parseError) {
                            // If parsing fails, log and skip
                            console.error('[InputBox] JSON parse error for tool result:', parseError);
                            console.error(
                              '[InputBox] Raw result:',
                              toolResult.result.substring(0, 200)
                            );
                            continue;
                          }
                        } else {
                          // Already an object
                          resultData = toolResult.result;
                        }

                        console.log('[InputBox] Parsed image generation result:', resultData);

                        if (resultData.success && resultData.imageBase64) {
                          generatedImages.push({
                            id: `generated-${Date.now()}-${Math.random()}`,
                            path: '',
                            filename: `Generated: ${resultData.prompt?.substring(0, 30) || 'image'}...`,
                            mimeType: 'image/png',
                            base64: resultData.imageBase64,
                          });
                          console.log('[InputBox] Added generated image to message');
                        }
                      } catch (error) {
                        console.error('[InputBox] Failed to process image generation result:', error);
                      }
                    }
                  }

                  if (generatedImages.length > 0) {
                    scheduleUpdate({ images: generatedImages });
                    // ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ í›„ í† ê¸€ ìë™ ë¹„í™œì„±í™”
                    setEnableImageGeneration(false);
                    console.log('[InputBox] Image generation completed, disabling toggle');
                  }
                }

                // ì—ëŸ¬ ì²˜ë¦¬
                if (event.type === 'error') {
                  throw new Error(event.error || 'Graph execution failed');
                }
              } catch (parseError) {
                console.error('[InputBox] Failed to parse stream event:', parseError);
              }
            });

          const doneHandler = window.electronAPI.langgraph.onStreamDone(
            (data?: { conversationId?: string }) => {
              try {
                // Filter by conversationId - ignore done events from other conversations
                if (data?.conversationId && data.conversationId !== conversationId) {
                  return;
                }

                if (abortControllerRef.current?.signal.aborted) {
                  return;
                }

                // Final update to ensure all content is displayed
                scheduleUpdate({}, true);
              } catch (error) {
                console.error('[InputBox] Failed to handle stream done:', error);
              }
            }
          );

          const errorHandler = window.electronAPI.langgraph.onStreamError(
            (data: { error: string; conversationId?: string }) => {
              // Filter by conversationId - ignore error events from other conversations
              if (data?.conversationId && data.conversationId !== conversationId) {
                return;
              }

              const errorMsg = data?.error || 'Failed to get response from LLM';
              console.error('[InputBox] Stream error:', errorMsg);
              setError(errorMsg);

              // Update message with error
              updateMessage(
                assistantMessageId,
                {
                  content: `Error: ${errorMsg}`,
                },
                conversationId
              );
            }
          );

          // Start streaming via IPC with conversationId for isolation
          // Pass ComfyUI config and network config for image generation in Main Process
          let networkConfig: NetworkConfig | null = null;
          if (enableImageGeneration && comfyUIConfig) {
            try {
              const networkConfigStr = localStorage.getItem('sepilot_network_config');
              networkConfig = networkConfigStr ? JSON.parse(networkConfigStr) : null;
            } catch (e) {
              console.warn('[InputBox] Failed to parse network config:', e);
            }
          }
          // Get working directory from store for Coding Agent
          const currentStore = useChatStore.getState();
          const workingDirectory = currentStore.workingDirectory;
          await window.electronAPI.langgraph.stream(
            graphConfig,
            allMessages,
            conversationId,
            enableImageGeneration && comfyUIConfig ? comfyUIConfig : undefined,
            enableImageGeneration && networkConfig ? networkConfig : undefined,
            workingDirectory || undefined
          );

          // Save final message to database (use captured conversationId, not activeConversationId)
          if (window.electronAPI && conversationId) {
            const finalMessage: Message = {
              id: assistantMessageId,
              conversation_id: conversationId,
              role: 'assistant',
              content: accumulatedMessage.content || accumulatedContent,
              created_at: Date.now(),
              referenced_documents: accumulatedMessage.referenced_documents,
              images: accumulatedMessage.images, // ìƒì„±ëœ ì´ë¯¸ì§€ í¬í•¨
            };
            await window.electronAPI.chat.saveMessage(finalMessage);
          }
        } else {
          // Web: WebLLMClient ì§ì ‘ ì‚¬ìš©
          const webClient = getWebLLMClient();
          const historyMessages = allMessages.map((m) => ({
            role: m.role as 'system' | 'user' | 'assistant',
            content: m.content,
          }));

          for await (const chunk of webClient.stream(historyMessages)) {
            if (abortControllerRef.current?.signal.aborted) {
              break;
            }

            if (!chunk.done && chunk.content) {
              accumulatedContent += chunk.content;
              scheduleUpdate({ content: accumulatedContent });
            }
          }

          // Final update to ensure all content is displayed
          scheduleUpdate({}, true);
        }

        // Auto-generate title if needed (after first successful response)
        if (conversationId) {
          const currentConversation = conversations.find((c) => c.id === conversationId);
          if (currentConversation && shouldGenerateTitle(currentConversation.title)) {
            // Get all messages including the ones we just added
            const allMessagesForTitle = [
              ...messages,
              { role: 'user' as const, content: userMessage },
              { role: 'assistant' as const, content: accumulatedContent },
            ];

            // Generate title in background (don't await)
            generateConversationTitle(allMessagesForTitle)
              .then((title) => {
                updateConversationTitle(conversationId, title);
              })
              .catch((err) => {
                console.error('Failed to auto-generate title:', err);
              });
          }
        }
      } catch (streamError: any) {
        console.error('Streaming error:', streamError);
        setError(streamError.message || 'Failed to get response from LLM');

        // Update message with error (specify conversation ID)
        updateMessage(
          assistantMessageId,
          {
            content: `Error: ${streamError.message || 'Failed to get response'}`,
          },
          conversationId
        );
      }
    } catch (error: any) {
      console.error('Send message error:', error);
      setError(error.message || 'Failed to send message');
    } finally {
      // Cleanup: cancel any pending animation frame
      if (rafId !== null) {
        cancelAnimationFrame(rafId);
      }

      // Cleanup: remove all IPC event listeners (Electron only)
      if (isElectron() && typeof window !== 'undefined' && window.electronAPI?.langgraph) {
        window.electronAPI.langgraph.removeAllStreamListeners();
      }

      // Stop streaming for this conversation
      stopStreaming(conversationId);
      streamingConversationIdRef.current = null;
      abortControllerRef.current = null;

      // Only restore focus if still on the same conversation
      // (user might have switched to another conversation)
      setTimeout(() => {
        const currentStore = useChatStore.getState();
        if (currentStore.activeConversationId === conversationId) {
          textareaRef.current?.focus();
        }
      }, 0);
    }
  };

  const handleKeyDown = (e: KeyboardEvent<HTMLTextAreaElement>) => {
    // IME composition ì¤‘ì¼ ë•ŒëŠ” Enter í‚¤ë¥¼ ë¬´ì‹œ (Mac í•œê¸€ ì…ë ¥ ë¬¸ì œ í•´ê²°)
    if (e.key === 'Enter' && !e.shiftKey && !isComposing) {
      e.preventDefault();
      handleSend();
    }
  };

  // Handle tool approval
  const handleToolApprove = useCallback(async (toolCalls: ToolCall[]) => {
    if (!pendingToolApproval) return;

    console.log('[InputBox] Approving tools:', toolCalls.map(tc => tc.name));

    try {
      if (isElectron() && window.electronAPI?.langgraph) {
        await window.electronAPI.langgraph.respondToolApproval(
          pendingToolApproval.conversationId,
          true
        );
      }
    } catch (error) {
      console.error('[InputBox] Failed to respond to tool approval:', error);
    }

    clearPendingToolApproval();
  }, [pendingToolApproval, clearPendingToolApproval]);

  // Handle tool rejection
  const handleToolReject = useCallback(async () => {
    if (!pendingToolApproval) return;

    console.log('[InputBox] Rejecting tools');

    try {
      if (isElectron() && window.electronAPI?.langgraph) {
        await window.electronAPI.langgraph.respondToolApproval(
          pendingToolApproval.conversationId,
          false
        );
      }
    } catch (error) {
      console.error('[InputBox] Failed to respond to tool rejection:', error);
    }

    clearPendingToolApproval();
  }, [pendingToolApproval, clearPendingToolApproval]);

  // Handle always approve (session-wide)
  const handleToolAlwaysApprove = useCallback(async (toolCalls: ToolCall[]) => {
    if (!pendingToolApproval) return;

    console.log('[InputBox] Always approving tools for session');

    // Set session-wide auto-approval
    setAlwaysApproveToolsForSession(true);

    // Approve current tools
    try {
      if (isElectron() && window.electronAPI?.langgraph) {
        await window.electronAPI.langgraph.respondToolApproval(
          pendingToolApproval.conversationId,
          true
        );
      }
    } catch (error) {
      console.error('[InputBox] Failed to respond to tool approval:', error);
    }

    clearPendingToolApproval();
  }, [pendingToolApproval, clearPendingToolApproval, setAlwaysApproveToolsForSession]);

  return (
    <>
      {/* Tool Approval Dialog */}
      {pendingToolApproval && (
        <ToolApprovalDialog
          onApprove={handleToolApprove}
          onReject={handleToolReject}
          onAlwaysApprove={handleToolAlwaysApprove}
        />
      )}

      <div
        ref={dropZoneRef}
        className={`shrink-0 border-t bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60 transition-colors ${
          isDragging ? 'bg-primary/10 border-primary' : ''
        }`}
        onDragOver={handleDragOver}
        onDragEnter={handleDragEnter}
        onDragLeave={handleDragLeave}
        onDrop={handleDrop}
      >
        <div className="mx-auto max-w-3xl px-4 py-4 relative">
          {isDragging && (
            <div className="absolute inset-0 flex items-center justify-center bg-primary/5 border-2 border-dashed border-primary rounded-lg z-10 pointer-events-none">
              <div className="text-center">
                <p className="text-sm font-medium text-primary">í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—¬ê¸°ì— ë“œë¡­í•˜ì„¸ìš”</p>
                <p className="text-xs text-muted-foreground mt-1">.txt, .md, .json, .js, .ts ë“±</p>
              </div>
            </div>
          )}

        {error && (
          <div className="mb-3 rounded-lg bg-destructive/10 px-4 py-3 text-sm text-destructive border border-destructive/20">
            {error}
          </div>
        )}
        {/* Selected Images Preview */}
        {selectedImages.length > 0 && (
          <div className="mb-2 flex flex-wrap gap-2">
            {mounted ? (
              <TooltipProvider>
                {selectedImages.map((image, index) => (
                  <Tooltip key={image.id}>
                    <TooltipTrigger asChild>
                      <div className="relative inline-flex items-center gap-1.5 rounded-lg bg-accent px-3 py-1.5 text-sm group hover:bg-accent/80 transition-colors">
                        <ImagePlus className="h-3.5 w-3.5" />
                        <span className="font-medium">ì´ë¯¸ì§€ #{index + 1}</span>
                        <button
                          onClick={() => handleRemoveImage(image.id)}
                          className="ml-1 rounded-sm opacity-70 hover:opacity-100 transition-opacity"
                          disabled={isStreaming}
                          title="ì´ë¯¸ì§€ ì œê±°"
                          aria-label="ì´ë¯¸ì§€ ì œê±°"
                        >
                          <X className="h-3.5 w-3.5" />
                        </button>
                      </div>
                    </TooltipTrigger>
                    <TooltipContent side="top" className="p-0 border-0 shadow-lg">
                      <div className="max-w-xs">
                        <img
                          src={image.base64}
                          alt={image.filename}
                          className="rounded-md max-h-48 w-auto"
                        />
                        <div className="p-2 text-xs text-muted-foreground bg-background/95 backdrop-blur">
                          {image.filename}
                        </div>
                      </div>
                    </TooltipContent>
                  </Tooltip>
                ))}
              </TooltipProvider>
            ) : (
              // Fallback for SSR - no tooltip
              selectedImages.map((image, index) => (
                <div
                  key={image.id}
                  className="relative inline-flex items-center gap-1.5 rounded-lg bg-accent px-3 py-1.5 text-sm group hover:bg-accent/80 transition-colors"
                >
                  <ImagePlus className="h-3.5 w-3.5" />
                  <span className="font-medium">ì´ë¯¸ì§€ #{index + 1}</span>
                  <button
                    onClick={() => handleRemoveImage(image.id)}
                    className="ml-1 rounded-sm opacity-70 hover:opacity-100 transition-opacity"
                    disabled={isStreaming}
                    title="ì´ë¯¸ì§€ ì œê±°"
                    aria-label="ì´ë¯¸ì§€ ì œê±°"
                  >
                    <X className="h-3.5 w-3.5" />
                  </button>
                </div>
              ))
            )}
          </div>
        )}
        <div className="relative flex items-end gap-2 rounded-2xl border border-input bg-background shadow-sm focus-within:ring-2 focus-within:ring-ring focus-within:ring-offset-2 transition-all">
          <Textarea
            ref={textareaRef}
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyDown={handleKeyDown}
            onPaste={handlePaste}
            onCompositionStart={() => setIsComposing(true)}
            onCompositionEnd={() => setIsComposing(false)}
            placeholder={
              selectedImages.length > 0
                ? 'ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...'
                : 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...'
            }
            className="flex-1 min-h-[52px] max-h-[200px] resize-none border-0 bg-transparent px-4 py-3 text-sm focus-visible:ring-0 focus-visible:ring-offset-0 placeholder:text-muted-foreground/60"
            disabled={isStreaming}
            rows={1}
          />
          <div className="flex items-center gap-1 pb-2 pr-2">
            {/* Thinking Mode Selector */}
            {mounted && (
              <DropdownMenu>
                <DropdownMenuTrigger asChild>
                  <Button
                    variant="ghost"
                    size="icon"
                    className="h-9 w-9 rounded-xl shrink-0"
                    title={
                      enableImageGeneration
                        ? 'ì´ë¯¸ì§€ ìƒì„± ëª¨ë“œì—ì„œëŠ” Instant ëª¨ë“œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤'
                        : `ì‚¬ê³  ëª¨ë“œ: ${
                            thinkingMode === 'instant'
                              ? 'Instant'
                              : thinkingMode === 'sequential'
                                ? 'Sequential'
                                : thinkingMode === 'tree-of-thought'
                                  ? 'Tree of Thought'
                                  : thinkingMode === 'deep'
                                    ? 'Deep Thinking'
                                    : 'Coding (beta)'
                          }`
                    }
                    disabled={isStreaming || enableImageGeneration}
                  >
                    {thinkingMode === 'instant' && <Zap className="h-4 w-4" />}
                    {thinkingMode === 'sequential' && <Brain className="h-4 w-4" />}
                    {thinkingMode === 'tree-of-thought' && <Network className="h-4 w-4" />}
                    {thinkingMode === 'deep' && <Sparkles className="h-4 w-4" />}
                    {thinkingMode === 'coding' && <Code className="h-4 w-4" />}
                    <ChevronDown className="h-3 w-3 ml-0.5 opacity-50" />
                  </Button>
                </DropdownMenuTrigger>
                <DropdownMenuContent align="end" side="top" className="w-56">
                  <DropdownMenuItem
                    onClick={() => setThinkingMode('instant')}
                    className={thinkingMode === 'instant' ? 'bg-accent' : ''}
                  >
                    <Zap className="mr-2 h-4 w-4 text-yellow-500" />
                    <div className="flex flex-col">
                      <span className="font-medium">Instant</span>
                      <span className="text-xs text-muted-foreground">ì¦‰ì‹œ ì‘ë‹µ - ë¹ ë¥¸ ëŒ€í™”</span>
                    </div>
                  </DropdownMenuItem>
                  <DropdownMenuItem
                    onClick={() => setThinkingMode('sequential')}
                    className={thinkingMode === 'sequential' ? 'bg-accent' : ''}
                  >
                    <Brain className="mr-2 h-4 w-4 text-blue-500" />
                    <div className="flex flex-col">
                      <span className="font-medium">Sequential Thinking</span>
                      <span className="text-xs text-muted-foreground">
                        ìˆœì°¨ì  ì‚¬ê³  - ë‹¨ê³„ë³„ ì¶”ë¡ 
                      </span>
                    </div>
                  </DropdownMenuItem>
                  <DropdownMenuItem
                    onClick={() => setThinkingMode('tree-of-thought')}
                    className={thinkingMode === 'tree-of-thought' ? 'bg-accent' : ''}
                  >
                    <Network className="mr-2 h-4 w-4 text-purple-500" />
                    <div className="flex flex-col">
                      <span className="font-medium">Tree of Thought</span>
                      <span className="text-xs text-muted-foreground">ë‹¤ì¤‘ ê²½ë¡œ íƒìƒ‰</span>
                    </div>
                  </DropdownMenuItem>
                  <DropdownMenuItem
                    onClick={() => setThinkingMode('deep')}
                    className={thinkingMode === 'deep' ? 'bg-accent' : ''}
                  >
                    <Sparkles className="mr-2 h-4 w-4 text-pink-500" />
                    <div className="flex flex-col">
                      <span className="font-medium">Deep Thinking</span>
                      <span className="text-xs text-muted-foreground">
                        ê¹Šì€ ì‚¬ê³  - ìµœê³  í’ˆì§ˆ (ëŠë¦¼)
                      </span>
                    </div>
                  </DropdownMenuItem>
                  <DropdownMenuItem
                    onClick={() => {
                      setThinkingMode('coding');
                      // Coding ëª¨ë“œëŠ” ìë™ìœ¼ë¡œ Toolsë¥¼ í™œì„±í™”
                      setEnableTools(true);
                    }}
                    className={thinkingMode === 'coding' ? 'bg-accent' : ''}
                  >
                    <Code className="mr-2 h-4 w-4 text-green-500" />
                    <div className="flex flex-col">
                      <span className="font-medium">Coding (beta)</span>
                      <span className="text-xs text-muted-foreground">
                        ë³µì¡í•œ ì½”ë”© ì‘ì—… - ReAct Agent
                      </span>
                    </div>
                  </DropdownMenuItem>
                </DropdownMenuContent>
              </DropdownMenu>
            )}

            {/* RAG Toggle */}
            {mounted && (
              <TooltipProvider>
                <Tooltip>
                  <TooltipTrigger asChild>
                    <Button
                      onClick={() => setEnableRAG(!enableRAG)}
                      variant="ghost"
                      size="icon"
                      className={`h-9 w-9 rounded-xl shrink-0 transition-colors ${
                        enableRAG ? 'bg-blue-500/10 text-blue-500 hover:bg-blue-500/20' : ''
                      }`}
                      title={enableRAG ? 'RAG ë¹„í™œì„±í™”' : 'RAG í™œì„±í™”'}
                      aria-label={enableRAG ? 'RAG ë¹„í™œì„±í™”' : 'RAG í™œì„±í™”'}
                      disabled={isStreaming}
                    >
                      <Database className="h-4 w-4" />
                    </Button>
                  </TooltipTrigger>
                  <TooltipContent side="top">
                    <p className="font-medium">RAG ê²€ìƒ‰</p>
                    <p className="text-xs text-muted-foreground">
                      ë¬¸ì„œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤
                    </p>
                  </TooltipContent>
                </Tooltip>
              </TooltipProvider>
            )}

            {/* Tools Toggle */}
            {mounted && (
              <TooltipProvider>
                <Tooltip>
                  <TooltipTrigger asChild>
                    <Button
                      onClick={() => setEnableTools(!enableTools)}
                      variant="ghost"
                      size="icon"
                      className={`h-9 w-9 rounded-xl shrink-0 transition-colors ${
                        enableTools ? 'bg-orange-500/10 text-orange-500 hover:bg-orange-500/20' : ''
                      }`}
                      title={enableTools ? 'Tools ë¹„í™œì„±í™”' : 'Tools í™œì„±í™”'}
                      aria-label={enableTools ? 'Tools ë¹„í™œì„±í™”' : 'Tools í™œì„±í™”'}
                      disabled={isStreaming}
                    >
                      <Wrench className="h-4 w-4" />
                    </Button>
                  </TooltipTrigger>
                  <TooltipContent side="top">
                    <p className="font-medium">MCP Tools</p>
                    <p className="text-xs text-muted-foreground">
                      AIê°€ ì™¸ë¶€ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
                    </p>
                  </TooltipContent>
                </Tooltip>
              </TooltipProvider>
            )}

            {/* Image Upload Button */}
            {mounted && isElectron() && (
              <Button
                onClick={handleImageSelect}
                variant="ghost"
                size="icon"
                className="h-9 w-9 rounded-xl shrink-0"
                title="ì´ë¯¸ì§€ ì¶”ê°€"
                disabled={isStreaming}
              >
                <ImagePlus className="h-4 w-4" />
              </Button>
            )}
            {/* Image Generation Toggle - Only show if ComfyUI is available */}
            {mounted && isElectron() && comfyUIAvailable && (
              <Button
                onClick={() => {
                  const newValue = !enableImageGeneration;
                  setEnableImageGeneration(newValue);
                  // ì´ë¯¸ì§€ ìƒì„± í™œì„±í™” ì‹œ ìë™ìœ¼ë¡œ Toolsë„ í™œì„±í™” (Agent ê·¸ë˜í”„ ì‚¬ìš©)
                  if (newValue && !enableTools) {
                    setEnableTools(true);
                  }
                }}
                variant="ghost"
                size="icon"
                className={`h-9 w-9 rounded-xl shrink-0 transition-colors ${
                  enableImageGeneration ? 'bg-primary/10 text-primary hover:bg-primary/20' : ''
                }`}
                title={enableImageGeneration ? 'ì´ë¯¸ì§€ ìƒì„± ë¹„í™œì„±í™”' : 'ì´ë¯¸ì§€ ìƒì„± í™œì„±í™” (Tools ìë™ í™œì„±í™”)'}
                disabled={isStreaming}
              >
                <Sparkles className="h-4 w-4" />
              </Button>
            )}

            {/* Send/Stop Button */}
            {isStreaming ? (
              <Button
                onClick={handleStop}
                variant="destructive"
                size="icon"
                className="h-9 w-9 rounded-xl shrink-0"
                title="ì¤‘ì§€ (Esc)"
              >
                <Square className="h-4 w-4" />
              </Button>
            ) : (
              <Button
                onClick={handleSend}
                disabled={!input.trim() && selectedImages.length === 0}
                size="icon"
                className="h-9 w-9 rounded-xl shrink-0 bg-primary hover:bg-primary/90 disabled:opacity-50"
                title="ì „ì†¡ (Enter)"
              >
                <Send className="h-4 w-4" />
              </Button>
            )}
          </div>
        </div>
        {/* Image Generation Progress */}
        {currentImageGenProgress && currentImageGenProgress.status !== 'completed' && (
          <ImageGenerationProgressBar
            progress={currentImageGenProgress}
            className="mt-3"
          />
        )}
        <LLMStatusBar
          isStreaming={isStreaming}
          llmConfig={llmConfig}
          messages={messages}
          input={input}
          mounted={mounted}
          tools={tools}
          onCompact={handleCompact}
          onConfigUpdate={handleConfigUpdate}
        />
      </div>
      </div>
    </>
  );
}
