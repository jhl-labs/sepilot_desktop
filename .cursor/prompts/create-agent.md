# Create AI Agent Prompt

LangGraph ê¸°ë°˜ AI Agent ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸

## ì‚¬ìš© ë°©ë²•

1. Cursor Chat ì—´ê¸° (Ctrl/Cmd + L)
2. `AGENT.md` ë¬¸ì„œ ì°¸ê³ 
3. ì•„ë˜ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ì—¬ ì‚¬ìš©

## í”„ë¡¬í”„íŠ¸

```
SEPilot Desktop í”„ë¡œì íŠ¸ì˜ AI Agentë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

**Agent ì´ë¦„**: [Agent ì´ë¦„]

**ì„¤ëª…**: [Agentê°€ ìˆ˜í–‰í•  ì‘ì—…]

**ìš”êµ¬ì‚¬í•­**:
- LangGraph ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° íŒ¨í„´
- AgentState íƒ€ì… ì •ì˜
- Tool ì •ì˜ ë° ì‹¤í–‰ ë¡œì§
- Human-in-the-Loop (í•„ìš”ì‹œ ì‚¬ìš©ì ìŠ¹ì¸)
- ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ì œí•œ
- ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤ì‹œê°„ í”¼ë“œë°±
- ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹…

**Agent State í•„ë“œ**:
- [í•„ë“œ 1]: [íƒ€ì… ë° ì„¤ëª…]
- [í•„ë“œ 2]: [íƒ€ì… ë° ì„¤ëª…]

**ì‚¬ìš©í•  Tools**:
- [Tool 1]: [ì„¤ëª…]
- [Tool 2]: [ì„¤ëª…]

**Agent ê·¸ë˜í”„ íŒ¨í„´**:
- [ ] Deep Thinking (CoT)
- [ ] Sequential Thinking
- [ ] Tree of Thought
- [x] Basic Loop (Generate â†’ Tools â†’ Repeat)
- [ ] Coding Agent (Planning â†’ Execution â†’ Verification)

ë‹¤ìŒ íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
1. Agent í´ë˜ìŠ¤: `lib/langgraph/agents/[agent-name].ts`
2. Agent State: `lib/langgraph/state/[agent-name]-state.ts`
3. Tools: `lib/langgraph/tools/[agent-name]-tools.ts`
4. í…ŒìŠ¤íŠ¸: `tests/lib/langgraph/agents/[agent-name].test.ts`
```

## ì˜ˆì‹œ

### Input

```
SEPilot Desktop í”„ë¡œì íŠ¸ì˜ AI Agentë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

**Agent ì´ë¦„**: CodeAnalyzerAgent

**ì„¤ëª…**: ì½”ë“œë² ì´ìŠ¤ë¥¼ ë¶„ì„í•˜ê³  ê°œì„  ì‚¬í•­ì„ ì œì•ˆí•˜ëŠ” Agent

**Agent State í•„ë“œ**:
- analysisResults: { issues: Issue[], suggestions: Suggestion[] }
- scannedFiles: string[]
- currentFile: string | null

**ì‚¬ìš©í•  Tools**:
- file_read: íŒŒì¼ ë‚´ìš© ì½ê¸°
- grep_search: ì½”ë“œ íŒ¨í„´ ê²€ìƒ‰
- ast_parse: AST íŒŒì‹± (TypeScript/JavaScript)

**Agent ê·¸ë˜í”„ íŒ¨í„´**:
- [x] Sequential Thinking (1. Scan â†’ 2. Analyze â†’ 3. Suggest)

íŒŒì¼ ìœ„ì¹˜: `lib/langgraph/agents/code-analyzer-agent.ts`
```

### Expected Structure

```typescript
// lib/langgraph/agents/code-analyzer-agent.ts
import { AgentState } from '@/lib/langgraph/state';
import { getLLMClient } from '@/lib/llm/client';
import { emitStreamingChunk } from '@/lib/llm/streaming-callback';
import { logger } from '@/lib/utils/logger';

export interface CodeAnalyzerAgentState extends AgentState {
  analysisResults?: {
    issues: Issue[];
    suggestions: Suggestion[];
  };
  scannedFiles?: string[];
  currentFile?: string | null;
}

export class CodeAnalyzerAgent {
  private maxIterations = 50;

  async *stream(initialState: CodeAnalyzerAgentState): AsyncGenerator<any, void, unknown> {
    let state = { ...initialState };

    // Phase 1: Scan
    emitStreamingChunk('\nğŸ” **ì½”ë“œë² ì´ìŠ¤ ìŠ¤ìº” ì¤‘...**\n', state.conversationId);
    const scanResult = await this.scanCodebase(state);
    state = { ...state, ...scanResult };

    // Phase 2: Analyze
    emitStreamingChunk('\nğŸ“Š **ì½”ë“œ ë¶„ì„ ì¤‘...**\n', state.conversationId);
    const analysisResult = await this.analyzeCode(state);
    state = { ...state, ...analysisResult };

    // Phase 3: Suggest
    emitStreamingChunk('\nğŸ’¡ **ê°œì„  ì‚¬í•­ ì œì•ˆ ì¤‘...**\n', state.conversationId);
    const suggestionsResult = await this.generateSuggestions(state);
    state = { ...state, ...suggestionsResult };

    yield { type: 'final_result', state };
  }

  // ... implementation
}
```
