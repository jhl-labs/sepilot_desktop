import { StateGraph, END } from '@langchain/langgraph';
import { AgentStateAnnotation, AgentState } from '../state';
import { toolsNode } from '../nodes/tools';
import type { Message } from '@/types';
import { emitStreamingChunk } from '@/lib/llm/streaming-callback';
import { LLMService } from '@/lib/llm/service';
import {
  getUserLanguage,
  getLanguageInstruction,
  getFollowUpLanguageInstruction,
} from '../utils/language-utils';
import { retrieveContextIfEnabled } from '../utils/rag-utils';
import { logger } from '@/lib/utils/logger';
const MAX_ITERATIONS = 3;

/**
 * 1ë‹¨ê³„: ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½ (Plan Node)
 */
async function planNode(state: AgentState): Promise<Partial<AgentState>> {
  let iteration = state.planningNotes?.iteration || 0;
  const isFirstStep = iteration === 0;
  const query = state.messages[state.messages.length - 1].content;

  // ì´ì „ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸ - ëª¨ë‘ ì‹¤íŒ¨í–ˆë‹¤ë©´ iterationì„ ì¦ê°€ì‹œí‚¤ì§€ ì•ŠìŒ (ì¬ì‹œë„)
  const toolResults = state.toolResults || [];
  const lastBatchStart = state.planningNotes?.lastSearchCount || 0;
  const lastBatchResults = toolResults.slice(lastBatchStart);
  const allFailed = lastBatchResults.length > 0 && lastBatchResults.every((r) => !!r.error);

  if (allFailed && !isFirstStep) {
    logger.info(
      '[DeepWebResearch] Previous searches all failed. Retrying without incrementing iteration.'
    );
    emitStreamingChunk(
      `âš ï¸ **ì´ì „ ê²€ìƒ‰ ì‹¤íŒ¨. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤...**\n\n`,
      state.conversationId
    );
    // iterationì„ ì¦ê°€ì‹œí‚¤ì§€ ì•Šê³  ì¬ì‹œë„
  } else if (!isFirstStep) {
    // ì„±ê³µì ì¸ ê²€ìƒ‰ì´ ìˆì—ˆìœ¼ë©´ iteration ì¦ê°€
    iteration += 1;
  }

  // RAG Context (ì²« í„´ì—ë§Œ ìˆ˜í–‰)
  let ragContext = '';
  if (isFirstStep) {
    ragContext = await retrieveContextIfEnabled(query, 'DeepWebResearch');
  }

  logger.info(`[DeepWebResearch] Planning Step (Iter ${iteration + 1}, Actual: ${iteration})`);

  if (isFirstStep) {
    emitStreamingChunk('\n\n## ğŸ§  ì‹¬ì¸µ ì›¹ ì—°êµ¬ ì‹œì‘\n\n', state.conversationId);
  } else {
    emitStreamingChunk(
      `\n\n### ğŸ”„ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ (ë‹¨ê³„ ${iteration + 1}/${MAX_ITERATIONS})\n\n`,
      state.conversationId
    );
  }

  // ì´ì „ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ ë¬¸ìì—´ ìƒì„± (ìœ„ì—ì„œ ì´ë¯¸ ì„ ì–¸í•œ toolResults ì¬ì‚¬ìš©)
  const previousResults = toolResults
    .map(
      (r, i) =>
        `[ê²€ìƒ‰ ê²°ê³¼ ${i + 1}] (${r.toolName}):\n${typeof r.result === 'string' ? r.result.substring(0, 1000) : JSON.stringify(r.result).substring(0, 1000)}...`
    )
    .join('\n\n');

  const systemMessage: Message = {
    id: 'system-plan',
    role: 'system',
    content: `ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ 'Deep Web Researcher'ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê¹Šì´ ìˆê³  í¬ê´„ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ê¸° ìœ„í•´ ë‹¨ê³„ë³„ë¡œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

í˜„ì¬ ë‹¨ê³„: ${iteration + 1} / ${MAX_ITERATIONS}

[í•µì‹¬ ì›ì¹™: ê¹Šì´ ìˆëŠ” ë‹¤ê°ë„ íƒìƒ‰]
- ì²« ê²€ìƒ‰ì—ì„œ ë§Œì¡±í•˜ì§€ ë§ê³ , ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.
- ìµœì†Œ 2-3ë²ˆì˜ ê²€ìƒ‰ì„ í†µí•´ ì •ë³´ì˜ ê¹Šì´ì™€ í­ì„ í™•ë³´í•˜ì„¸ìš”.
- ê° iterationë§ˆë‹¤ ìƒˆë¡œìš´ í‚¤ì›Œë“œë‚˜ ê´€ì ìœ¼ë¡œ ì ‘ê·¼í•˜ì„¸ìš”.
- ì§„ì§œ ì¶©ë¶„í•œ ì •ë³´ê°€ ëª¨ì˜€ì„ ë•Œë§Œ ê²€ìƒ‰ì„ ì¢…ë£Œí•˜ì„¸ìš”.

[ì§€ì‹œì‚¬í•­]
1. í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬, ë” í•„ìš”í•œ ì •ë³´ê°€ ë¬´ì—‡ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.
2. **ì •ë³´ê°€ ì§„ì§œ ì¶©ë¶„í•  ë•Œë§Œ** 'queries'ë¥¼ ë¹ˆ ë°°ì—´ []ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
   - ë‹¨ìˆœíˆ "ë­”ê°€ ë‚˜ì™”ë‹¤"ê°€ ì•„ë‹ˆë¼ "ì§ˆë¬¸ì— ì™„ì „íˆ ë‹µí•  ìˆ˜ ìˆë‹¤"ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”.
   - ì²« ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶ˆì¶©ë¶„í•˜ê±°ë‚˜ ì¼ë¶€ ê´€ì ë§Œ ë‹¤ë£¬ë‹¤ë©´ ê³„ì† ê²€ìƒ‰í•˜ì„¸ìš”.
3. ë” ì •ë³´ê°€ í•„ìš”í•˜ë‹¤ë©´, Tavily ê²€ìƒ‰ ë„êµ¬ë¥¼ ìœ„í•œ ìµœì ì˜ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.

4. **ğŸš¨ ì ˆëŒ€ ì¤€ìˆ˜ ì‚¬í•­ (íŒŒë¼ë¯¸í„° ì œí•œ) ğŸš¨**
   'tavily_search' ë„êµ¬ëŠ” **ì˜¤ì§ 2ê°œì˜ íŒŒë¼ë¯¸í„°ë§Œ** í—ˆìš©í•©ë‹ˆë‹¤:

   âœ… **í—ˆìš©ëœ íŒŒë¼ë¯¸í„° (ì´ê²ƒë§Œ ì‚¬ìš©):**
   - "query": (string, í•„ìˆ˜) ê²€ìƒ‰ì–´ - ë°˜ë“œì‹œ ì˜ë¯¸ ìˆëŠ” ë¬¸ìì—´ì„ ì…ë ¥í•˜ì„¸ìš”
   - "max_results": (number, ì„ íƒ) ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5, ë²”ìœ„: 1-10)

   âŒ **ê¸ˆì§€ëœ ëª¨ë“  íŒŒë¼ë¯¸í„° (ì‹œìŠ¤í…œ ì—ëŸ¬ ë°œìƒ):**
   ì•„ë˜ íŒŒë¼ë¯¸í„°ë“¤ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì‚¬ìš©í•˜ë©´ ê²€ìƒ‰ì´ ì‹¤íŒ¨í•©ë‹ˆë‹¤:
   - "top_n", "topn", "country", "topic", "search_depth", "days", "time_range"
   - "include_domains", "exclude_domains", "include_answer"
   - "include_raw_content", "include_images", "select_paths", "exclude_paths"
   - ê¸°íƒ€ query, max_results ì´ì™¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°

   **ë¹ˆ ê°’ë„ ì ˆëŒ€ ê¸ˆì§€:**
   - ë¹ˆ ë¬¸ìì—´ (""), null, undefined ê°’ì„ íŒŒë¼ë¯¸í„°ë¡œ ë³´ë‚´ì§€ ë§ˆì„¸ìš”
   - ì‚¬ìš©í•˜ì§€ ì•Šì„ íŒŒë¼ë¯¸í„°ëŠ” ì•„ì˜ˆ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”

   **âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ (ì´ í˜•ì‹ë§Œ ì‚¬ìš©í•˜ì„¸ìš”):**
   {"query": "latest AI news 2025", "max_results": 5} âœ…
   {"query": "Python tutorial beginners"} âœ… (max_results ìƒëµ ê°€ëŠ¥)
   {"query": "climate change statistics", "max_results": 3} âœ…

   **âŒ ì˜ëª»ëœ ì˜ˆì‹œ (ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€):**
   {"query": "news", "max_results": 5, "country": "ko"} âŒ (country íŒŒë¼ë¯¸í„° ì‚¬ìš©)
   {"query": "AI", "top_n": 10} âŒ (top_nì€ ê¸ˆì§€, max_results ì‚¬ìš©)
   {"query": "research", "time_range": ""} âŒ (time_range íŒŒë¼ë¯¸í„° + ë¹ˆ ë¬¸ìì—´)
   {"query": "search", "search_depth": "advanced"} âŒ (search_depth ê¸ˆì§€)
   {"query": "data", "select_paths": [], "exclude_paths": []} âŒ (paths íŒŒë¼ë¯¸í„° ê¸ˆì§€)
   {"query": "", "max_results": 5} âŒ (ë¹ˆ query ê¸ˆì§€)

   **âš ï¸ ì¤‘ìš”:
   - íŒŒë¼ë¯¸í„°ëŠ” queryì™€ max_resultsë§Œ ì‚¬ìš©í•˜ì„¸ìš”
   - ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ê°€í•˜ë©´ ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤
   - ë¹ˆ ê°’ì„ ë³´ë‚´ì§€ ë§ˆì„¸ìš”**

5. í•œ ë²ˆì— ìµœëŒ€ 3ê°œì˜ ë³‘ë ¬ ì¿¼ë¦¬ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
6. ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.

[JSON í˜•ì‹ ì˜ˆì‹œ]
{
  "thought": "ì‚¬ìš©ìê°€ ...ì— ëŒ€í•´ ë¬¼ì—ˆìœ¼ë¯€ë¡œ, ë¨¼ì € ìµœì‹  ë™í–¥ì„ ê²€ìƒ‰í•˜ê³ , ì´ì–´ì„œ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ê³¼ ì‹¤ì œ ì‚¬ë¡€ë¥¼ ì¶”ê°€ë¡œ ì¡°ì‚¬í•´ì•¼ í•©ë‹ˆë‹¤.",
  "queries": [
    {"tool_name": "tavily_search", "parameters": {"query": "Gemini 3.0 latest news 2025", "max_results": 5}},
    {"tool_name": "tavily_search", "parameters": {"query": "Gemini 3.0 technical specifications", "max_results": 5}}
  ]
}`,
    created_at: Date.now(),
  };

  const planPrompt: Message = {
    id: 'plan-prompt',
    role: 'user',
    content: `ì›ë³¸ ì§ˆë¬¸: ${query}

${ragContext ? `[ì‚¬ì „ RAG ì •ë³´]\n${ragContext}\n\n` : ''}
[í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´]
${previousResults || '(ì—†ìŒ)'}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ê²€ìƒ‰ ê³„íšì„ JSONìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.`,
    created_at: Date.now(),
  };

  let planOutput = '';
  // ë„êµ¬ í˜¸ì¶œ ì—†ì´ ìˆœìˆ˜ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•´ tools: []
  for await (const chunk of LLMService.streamChat([systemMessage, planPrompt], {
    tools: [],
    tool_choice: 'none',
  })) {
    // ê³„íš ìƒì„± ê³¼ì •ì€ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ì§€ ì•Šê±°ë‚˜ ê°„ëµíˆë§Œ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŒ
    // ì—¬ê¸°ì„œëŠ” ë””ë²„ê¹…ì„ ìœ„í•´ ë¡œê·¸ë¡œë§Œ ë‚¨ê¸°ê³ , ì‹¤ì œ ê³„íšëœ ì¿¼ë¦¬ëŠ” ì•„ë˜ì—ì„œ ì¶œë ¥
    planOutput += chunk;
  }

  logger.info('[DeepWebResearch] Plan Output:', planOutput);

  // íŒŒì‹±
  let plannedQueries: any[] = [];
  let thought = '';

  try {
    // JSON ì¶”ì¶œ
    const jsonMatch = planOutput.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0]);
      plannedQueries = parsed.queries || [];
      thought = parsed.thought || '';
    } else {
      console.warn('[DeepWebResearch] Failed to find JSON in plan output');
    }
  } catch (e) {
    console.error('[DeepWebResearch] JSON parse error:', e);
  }

  // í™”ë©´ì— ê³„íš ì•Œë¦¼
  if (thought) {
    emitStreamingChunk(`ğŸ¤” **ìƒê°:** ${thought}\n\n`, state.conversationId);
  }
  if (plannedQueries.length > 0) {
    const queryList = plannedQueries.map((q) => `- "${q.parameters.query}"`).join('\n');
    emitStreamingChunk(`ğŸ“ **ê²€ìƒ‰ ê³„íš:**\n${queryList}\n\n`, state.conversationId);
  } else {
    emitStreamingChunk(`âœ… **ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ. ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.**\n\n`, state.conversationId);
  }

  return {
    messages: state.messages, // ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ëŠ” ìœ ì§€
    planningNotes: {
      queries: plannedQueries,
      iteration,
      thought,
      lastSearchCount: toolResults.length, // í˜„ì¬ê¹Œì§€ì˜ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì €ì¥
    },
  };
}

/**
 * 2ë‹¨ê³„: ì›¹ ê²€ìƒ‰ ì‹¤í–‰ (Search Node)
 */
async function searchNode(state: AgentState): Promise<Partial<AgentState>> {
  const notes = state.planningNotes;
  const queries = notes?.queries || [];

  if (queries.length === 0) {
    return {};
  }

  logger.info(`[DeepWebResearch] Executing ${queries.length} searches...`);
  emitStreamingChunk(`ğŸš€ **ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...**\n`, state.conversationId);

  let newToolResults: any[] = [];

  // ë³‘ë ¬ ì‹¤í–‰ì„ ìœ„í•´ Promise.all ì‚¬ìš©
  // toolsNodeëŠ” tool_calls ë©”ì‹œì§€ë¥¼ ë°›ì•„ ì²˜ë¦¬í•˜ë¯€ë¡œ, ì§ì ‘ MCPServerManagerë‚˜ builtin toolsë¥¼ í˜¸ì¶œí•˜ëŠ” ê²Œ ë‚˜ì„ ìˆ˜ ìˆìŒ.
  // í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ì¼ê´€ì„±ì„ ìœ„í•´ toolsNode ë¡œì§ì„ í‰ë‚´ë‚´ê±°ë‚˜ ì¬ì‚¬ìš©.
  // ì—¬ê¸°ì„œëŠ” ê° ì¿¼ë¦¬ë¥¼ ê°œë³„ tool callë¡œ ë§Œë“¤ì–´ ì²˜ë¦¬.

  // ì£¼ì˜: ì‹¤ì œ ë„êµ¬ ì‹¤í–‰ì€ toolsNodeë¥¼ í†µí•´ì•¼ í™œë™ ë¡œê·¸ ë“±ì´ ë‚¨ìŒ.
  // í•˜ì§€ë§Œ toolsNodeëŠ” state.messagesì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ì˜ tool_callsë¥¼ ë´…ë‹ˆë‹¤.
  // ì—¬ê¸°ì„œëŠ” ì„ì‹œ ë©”ì‹œì§€ë¥¼ ë§Œë“¤ì–´ toolsNodeì— ë„˜ê¹ë‹ˆë‹¤.

  // Filter tool parameters to only include allowed fields
  const tempToolCalls = queries.map((q: any, idx: number) => {
    let cleanedParams = q.parameters;

    // Tavily Search: Only allow query and max_results
    if (q.tool_name === 'tavily_search') {
      const params = q.parameters || {};

      // Extract query (support multiple field names)
      let query = params.query || params.search_query || '';
      if (typeof query !== 'string') {
        query = String(query);
      }
      query = query.trim();

      // Extract max_results (support multiple field names and map old names)
      let maxResults = params.max_results || params.maxResults || params.top_n || params.topn || 5;
      if (typeof maxResults === 'string') {
        maxResults = parseInt(maxResults, 10) || 5;
      }
      maxResults = Math.max(1, Math.min(maxResults, 10)); // Clamp to 1-10

      // Only include non-empty values
      cleanedParams = {};
      if (query) {
        cleanedParams.query = query;
      }
      if (maxResults) {
        cleanedParams.max_results = maxResults;
      }

      logger.info('[DeepWebResearch] Original params:', params);
      logger.info('[DeepWebResearch] Cleaned params:', cleanedParams);
    }

    return {
      id: `call-${Date.now()}-${idx}`,
      name: q.tool_name,
      arguments: cleanedParams,
    };
  });

  const tempMessage: Message = {
    id: `temp-tool-msg-${Date.now()}`,
    role: 'assistant',
    content: '',
    tool_calls: tempToolCalls,
    created_at: Date.now(),
  };

  // toolsNode í˜¸ì¶œ
  try {
    const resultState = await toolsNode({
      ...state,
      messages: [...state.messages, tempMessage],
    } as any); // AgentState í˜¸í™˜ì„±

    newToolResults = resultState.toolResults || [];

    // ê²°ê³¼ ë¡œê¹…
    for (const res of newToolResults) {
      if (res.error) {
        emitStreamingChunk(`âŒ **ì‹¤íŒ¨:** ${res.toolName} - ${res.error}\n`, state.conversationId);
      } else {
        // ê²°ê³¼ê°€ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½í•´ì„œ ë³´ì—¬ì¤„ ìˆ˜ë„ ìˆìŒ
        emitStreamingChunk(`âœ… **ì™„ë£Œ:** ${res.toolName}\n`, state.conversationId);
      }
    }
  } catch (e: any) {
    emitStreamingChunk(`âŒ **ê²€ìƒ‰ ì‹¤íŒ¨:** ${e.message}\n`, state.conversationId);
    newToolResults.push({ error: e.message, toolName: 'tavily_search' } as any);

    // Rate Limitì´ë‚˜ ì¹˜ëª…ì  ì—ëŸ¬ ê°ì§€
    if (
      e.message.includes('429') ||
      e.message.toLowerCase().includes('limit') ||
      e.message.toLowerCase().includes('quota') ||
      e.message.toLowerCase().includes('unauthorized')
    ) {
      emitStreamingChunk(
        `âš ï¸ **ê²€ìƒ‰ ì œí•œ ê°ì§€:** ì¶”ê°€ ê²€ìƒ‰ì„ ì¤‘ë‹¨í•˜ê³  í˜„ì¬ ì •ë³´ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n`,
        state.conversationId
      );
      return {
        toolResults: [...(state.toolResults || []), ...newToolResults],
        planningNotes: { ...state.planningNotes, forceSynthesize: true },
      };
    }
  }

  return {
    // ê¸°ì¡´ toolResultsì— ëˆ„ì 
    toolResults: [...(state.toolResults || []), ...newToolResults],
  };
}

/**
 * ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜
 */
function checkPlan(state: AgentState) {
  const notes = state.planningNotes;

  // ê°•ì œ ì¢…ë£Œ í”Œë˜ê·¸ í™•ì¸
  if (notes?.forceSynthesize) {
    logger.info('[DeepWebResearch] Force synthesize flag detected');
    return 'synthesize';
  }

  // ì¿¼ë¦¬ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ (Synthesize) - LLMì´ ì¶©ë¶„í•˜ë‹¤ê³  íŒë‹¨
  if (!notes || !notes.queries || notes.queries.length === 0) {
    logger.info('[DeepWebResearch] No more queries planned. Moving to synthesize.');
    return 'synthesize';
  }

  // ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ ì¢…ë£Œ (>= ì‚¬ìš©í•˜ì—¬ ì •í™•íˆ MAX_ITERATIONSë§Œí¼ë§Œ ì‹¤í–‰)
  if (notes.iteration >= MAX_ITERATIONS) {
    logger.info(
      `[DeepWebResearch] Max iterations reached (${notes.iteration}/${MAX_ITERATIONS}). Moving to synthesize.`
    );
    emitStreamingChunk(
      `\nâ¸ï¸ **ìµœëŒ€ ê²€ìƒ‰ íšŸìˆ˜ ë„ë‹¬ (${notes.iteration}/${MAX_ITERATIONS}). ìˆ˜ì§‘ëœ ì •ë³´ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.**\n\n`,
      state.conversationId
    );
    return 'synthesize';
  }

  logger.info(
    `[DeepWebResearch] Proceeding to search (iteration ${notes.iteration + 1}/${MAX_ITERATIONS})`
  );
  return 'search';
}

/**
 * 3ë‹¨ê³„: ê²°ê³¼ ì¢…í•© ë° ë‹µë³€ ìƒì„± (Synthesize Node)
 */
async function synthesizeNode(state: AgentState): Promise<Partial<AgentState>> {
  logger.info('[DeepWebResearch] Step 3: Synthesizing answer...');
  emitStreamingChunk('\n\n## âœ¨ ìµœì¢… ë‹µë³€ ìƒì„±\n\n', state.conversationId);
  emitStreamingChunk(
    '**ë‹¨ê³„ ì§„í–‰ ì¤‘:** ìˆ˜ì§‘ëœ ë°©ëŒ€í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•©ë‹ˆë‹¤...\n\n',
    state.conversationId
  );

  // ì‚¬ìš©ì ì–¸ì–´ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
  const userLanguage = await getUserLanguage();
  const languageInstruction = getLanguageInstruction(userLanguage);

  const allSearchOutputs =
    state.toolResults
      ?.map((r) => {
        const content = typeof r.result === 'string' ? r.result : JSON.stringify(r.result);
        return `[ì¶œì²˜: ${r.toolName}]\n${content.substring(0, 2000)}... (ìƒëµë¨)`; // ì»¨í…ìŠ¤íŠ¸ ì œí•œ ê³ ë ¤
      })
      .join('\n\n---\n\n') || 'ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ';

  const systemMessage: Message = {
    id: 'system-synth',
    role: 'system',
    content: `ë‹¹ì‹ ì€ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ í¬ê´„ì ì´ê³  ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” AIì…ë‹ˆë‹¤.
ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ìš”ì•½í•˜ê³ , ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

ë§Œì•½ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ë¶ˆì¶©ë¶„í•˜ë‹¤ë©´(ê²€ìƒ‰ ì‹¤íŒ¨, ì œí•œ ë“±), ë‹¹ì‹ ì˜ ë‚´ë¶€ ì§€ì‹ì„ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ê³  ê²€ìƒ‰ì— ì–´ë ¤ì›€ì´ ìˆì—ˆìŒì„ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¬ì„¸ìš”. ${languageInstruction}`,
    created_at: Date.now(),
  };

  const synthesizePrompt: Message = {
    id: 'synth-prompt',
    role: 'user',
    content: `ì›ë³¸ ì§ˆë¬¸: ${state.messages[state.messages.length - 1].content}

[ìˆ˜ì§‘ëœ ì—°êµ¬ ìë£Œ]
${allSearchOutputs}

ìœ„ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.`,
    created_at: Date.now(),
  };

  let finalAnswer = '';
  // ì‚¬ê³  ëª¨ë¸ê³¼ ë‹¬ë¦¬ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ { tools: [], tool_choice: 'none' }
  for await (const chunk of LLMService.streamChat([systemMessage, synthesizePrompt], {
    tools: [],
    tool_choice: 'none',
  })) {
    finalAnswer += chunk;
    emitStreamingChunk(chunk, state.conversationId);
  }

  // í›„ì† ì§ˆë¬¸ ìƒì„± (Perplexity ìŠ¤íƒ€ì¼)
  let followUpQuestions = '';
  if (finalAnswer) {
    emitStreamingChunk('\n\n---\n### ğŸ’¡ ì¶”ì²œ í›„ì† ì§ˆë¬¸\n', state.conversationId);

    const tempAssistantMessage: Message = {
      id: 'temp-assistant',
      role: 'assistant',
      content: finalAnswer,
      created_at: Date.now(),
    };

    // ì‚¬ìš©ì ì–¸ì–´ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    const userLanguage = await getUserLanguage();
    const followUpLanguage = getFollowUpLanguageInstruction(userLanguage);

    const followUpPrompt: Message = {
      id: 'follow-up-prompt',
      role: 'user',
      content: `ìœ„ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì´ì–´ì„œ ê¶ê¸ˆí•´í•  ë§Œí•œ "ì¶”ì²œ í›„ì† ì§ˆë¬¸" 3ê°€ì§€ë¥¼ ${followUpLanguage} ì œì•ˆí•´ì£¼ì„¸ìš”.\nì§ˆë¬¸ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ ì‘ì„±í•˜ì„¸ìš”. (ì„¤ëª… ë¶ˆí•„ìš”)`,
      created_at: Date.now(),
    };

    try {
      for await (const chunk of LLMService.streamChat(
        [systemMessage, synthesizePrompt, tempAssistantMessage, followUpPrompt],
        { tools: [], tool_choice: 'none' }
      )) {
        followUpQuestions += chunk;
        emitStreamingChunk(chunk, state.conversationId);
      }
    } catch (e) {
      console.error('[DeepWebResearch] Failed to generate follow-up questions', e);
    }
  }

  const finalContent = followUpQuestions
    ? `${finalAnswer}\n\n---\n### ğŸ’¡ ì¶”ì²œ í›„ì† ì§ˆë¬¸\n${followUpQuestions}`
    : finalAnswer;

  const assistantMessage: Message = {
    id: `msg-${Date.now()}`,
    role: 'assistant',
    content: finalContent,
    created_at: Date.now(),
  };

  logger.info('[DeepWebResearch] Final answer synthesized');

  return {
    messages: [assistantMessage],
  };
}

/**
 * Deep Web Research Graph ìƒì„±
 */
export function createDeepWebResearchGraph() {
  const workflow = new StateGraph(AgentStateAnnotation)
    .addNode('plan', planNode)
    .addNode('search', searchNode)
    .addNode('synthesize', synthesizeNode)

    .addEdge('__start__', 'plan')

    // plan -> checkPlan -> (search | synthesize)
    .addConditionalEdges('plan', checkPlan, {
      search: 'search',
      synthesize: 'synthesize',
    })

    // search -> plan (Loop)
    .addEdge('search', 'plan')

    .addEdge('synthesize', END);

  return workflow.compile();
}
